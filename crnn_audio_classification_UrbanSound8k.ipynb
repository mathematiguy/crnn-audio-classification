{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will go over how to install this repo on an external server to run the training and inference.\n",
    "To begin, we'll first need to clone the repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need to install the [torchaudio-contrib package](https://github.com/keunwoochoi/torchaudio-contrib). This is simple as cloneing the repo and using `pip` to install it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll do some cleanup and move the repo into the root folder, which is optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll install the other required packages. Note tensorboardX is optional. If you want to install tensorboardX, you'll also need to install Tensorflow as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once its downloaded, we will then need to untar the file. Just replace `{urbansound8k_downloaded_file}` with the name of the file. \n",
    "Optionally, we can removed the downloaded file here as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the config file\n",
    "\n",
    "The config file is used to build out the training model. The only thing you will *need* to change is the path to the dataset.\n",
    "which is located in `data[\"path\"]`.\n",
    "You may also want to change the number of epochs(`data[\"train\"][\"epochs\"]`), when testing. Running the training with 10 epochs took about 10 minutes on a GPU. (You are running this on a GPU right :))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7rJflAUKC4kU"
   },
   "outputs": [],
   "source": [
    "json_config = {\n",
    "    \"name\"          :   \"Urban Testing\",\n",
    "    \"data\"          :   {\n",
    "                            \"type\"      :   \"CSVDataManager\",\n",
    "                            \"path\"      :   \"UrbanSound8K\",\n",
    "                            \"format\"    :   \"audio\",\n",
    "                            \"loader\"    :   {\n",
    "                                                \"shuffle\"       : True,\n",
    "                                                \"batch_size\"    : 24,\n",
    "                                                \"num_workers\"   : 4,\n",
    "                                                \"drop_last\"     : True\n",
    "                                            },\n",
    "                            \"splits\"    :   {\n",
    "                                                \"train\" : [1,2,3,4,5,6,7,8,9], \n",
    "                                                \"val\"   : [10]                                            \n",
    "                                            }\n",
    "                        },\n",
    "    \"transforms\"    :   {\n",
    "                            \"type\"      :   \"AudioTransforms\",\n",
    "                            \"args\"      :   {\n",
    "                                                \"channels\"       : \"avg\",\n",
    "                                                \"noise\"    : [0.3, 0.001],\n",
    "                                                \"crop\"     : [0.4, 0.25]\n",
    "                                            }\n",
    "                        },\n",
    "    \"optimizer\"     :   {\n",
    "                            \"type\"      :   \"Adam\",\n",
    "                            \"args\"      :   {\n",
    "                                                \"lr\"            : 0.002,\n",
    "                                                \"weight_decay\"  : 0.01,\n",
    "                                                \"amsgrad\"       : True\n",
    "                                            }\n",
    "                        },\n",
    "    \"lr_scheduler\"   :   {\n",
    "                            \"type\"      :   \"StepLR\",\n",
    "                            \"args\"      :   {\n",
    "                                                \"step_size\" : 10,\n",
    "                                                \"gamma\"     : 0.5\n",
    "                                            }\n",
    "                        },\n",
    "    \"model\"         :   {\n",
    "                            \"type\"      :   \"AudioCRNN\"\n",
    "                        },\n",
    "    \"train\"         :   {\n",
    "                            \"loss\"      :   \"nll_loss\",\n",
    "                            \"epochs\"    :   100,\n",
    "                            \"save_dir\"  :   \"saved_cv/\",\n",
    "                            \"save_p\"    :   1,\n",
    "                            \"verbosity\" :   2,\n",
    "                            \n",
    "                            \"monitor\"   :   \"min val_loss\",\n",
    "                            \"early_stop\":   8,\n",
    "                            \"tbX\"       :   True\n",
    "                        },\n",
    "    \"metrics\"       :   \"classification_metrics\"\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll write this json out, in order for the model to read in this updated json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Y43AjFuF9Yf"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('config.json', 'w') as json_file:  \n",
    "    json.dump(json_config, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Finally, we can start training the model. We'll be passing 3 parameters, with the first parameter being the action we want to take, which is `train`. You can use `train` to train the model, or `eval`, to perform evalation on the model. The `-c` parameter is the config file, which we just created, and `--cfg`, which is the layer configuration of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "GZ5AVLf5zjv6",
    "outputId": "8605180e-767a-4323-8b1d-49c771e946ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"run.py\", line 7, in <module>\n",
      "    import data as data_module\n",
      "  File \"/work/data/__init__.py\", line 1, in <module>\n",
      "    from .data_manager import *\n",
      "  File \"/work/data/data_manager.py\", line 2, in <module>\n",
      "    import os, cv2\n",
      "ModuleNotFoundError: No module named 'cv2'\n"
     ]
    }
   ],
   "source": [
    "!python3 run.py train -c my-config.json --cfg crnn.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "After we have trainined the model, we can run inference on it.\n",
    "Call the `run.py` with 2 parameters. The first is a path to a sample audio audio file. For this example, we'll use a random audio sample from the UrbanSound8K dataset. The second parameter will be the path to the model checkpoint. It will look something like this `saved_cv/{timestamp}/checkoints/model_best.pth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9H0Naj2rzq4K",
    "outputId": "a63019bc-67d5-4fd9-d8df-7d8212f7acad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog_bark 0.9858338236808777\n"
     ]
    }
   ],
   "source": [
    "!python run.py UrbanSound8K/audio/fold10/100795-3-0-0.wav -r saved_cv/0515_171217/checkpoints/model_best.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running our inference, we got a 98% confidence of the supplied audio to be a dog bark."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "crnn-audio-classification - UrbanSound8k.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
